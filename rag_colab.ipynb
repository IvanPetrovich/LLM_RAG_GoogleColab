{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Установка необходимых библиотек\n",
    "!pip install -q langchain chromadb langchain-chroma sentence-transformers transformers ipywidgets huggingface_hub"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2. Клонируем репозиторий с файлами\n",
    "!git clone https://github.com/IvanPetrovich/LLM_RAG_GoogleColab\n",
    "%cd LLM_RAG_GoogleColab"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3. Импорт библиотек\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import pipeline\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 4. Загрузка модели генерации текста\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"google/gemma-3\",\n",
    "    device=-1\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 5. Функция для загрузки текстовых файлов\n",
    "def load_file(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "upcoming_text = load_file(\"upcoming.txt\")\n",
    "released_text = load_file(\"released.txt\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 6. Разделение текста на документы\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "upcoming_docs = text_splitter.create_documents([upcoming_text])\n",
    "released_docs = text_splitter.create_documents([released_text])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 7. Создание векторных хранилищ\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db_upcoming = Chroma.from_documents(upcoming_docs, embeddings)\n",
    "db_released = Chroma.from_documents(released_docs, embeddings)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 8. Функция для поиска и генерации ответа\n",
    "def generate_answer(query, db):\n",
    "    docs = db.similarity_search(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    prompt = f\"На основе следующего контекста, ответь на вопрос:\\n{context}\\nВопрос: {query}\\nОтвет:\"\n",
    "    response = generator(prompt, max_length=500)\n",
    "    return response[0][\"generated_text\"]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 9. Пример использования\n",
    "query = \"Какие ожидаются новинки в играх?\"\n",
    "answer = generate_answer(query, db_upcoming)\n",
    "print(answer)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}